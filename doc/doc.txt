// vim:filetype=asciidoc expandtab
= Junkie The Network Sniffer
:toc:
:website: http://github.com/securactive/junkie

== Overview

=== What's a network sniffer? And what's Junkie?

If you are reading this you probably already know that a network sniffer is a
program that 'sniffs' packets (ie. reads them although they are destined to
another program and/or host). Most sniffers does this using the well known
libpcap library for packet capture, which is portable and efficient, and
Junkie is not different in this regard. Reasons to sniff network traffic range
from troubleshooting network problems to stealing confidential informations,
and most sniffers are build with a special purpose. For instance Wireshark is
very helpful to diagnose network problems while DSniff is useful to quickly
steal innocent users password (or check that no password can be stolen that
easily, depending how you look at it).

Junkie has no such predefined purpose; instead, it was designed to help
you build the sniffer you need by offering you a simpler view of the
network traffic than mere packets, while still being able to handle
a realistic network flow in realtime. So it stands somewhere in between
Tcpdump and Wireshark.

Here are the features that stand out:

- parse a handful of everyday protocols such as HTTP, DNS or SIP
- performs IP reassembly and TCP reordering
- comes with a tool to match any sequence of network events
- can be easily extended in C and/or Guile

You might find Junkie interesting if you:

- have to deal with a good amount of IP packets in realtime
- want to extract some informations
- want to react on some complex network event


=== How does Junkie compare to...

==== Wireshark

Wireshark can completely descramble hundreds of exotic protocols while Junkie
only gather the most useful informations of a few. But Junkie can do so in
realtime with no interruption on large amount of traffic while Wireshark
cannot.

Also, Wireshark can select packets using a simple, stateless language, while
Junkie can select packets or a succession of packets using a less simple but
stateful language (for instance, with junkie you can select all DNS answers
that are received more than 150ms after the corresponding request ; you cannot
do that with Wireshark).

==== Tcpdump

Tcpdump can only display/save packets. Junkie can do that as well, and much
more. But Tcpdump is faster and easier.

==== Netsniff-ng

Netsniff-ng is similar to Junkie in spirit, but lacks:

- custom stateful language to match network events
- extension language

Disclamer: I never used netsniff-ng

==== Bro

Bro is an extensible sniffer targeted as an IDS. It seams less general
purpose, yet if your goal is related to security you'd probably make sure you
tried Bro before Junkie. Also, Bro seams to have a broader community of users.

Disclamer: I never used bro

== Limitations

As a realtime protocol analyzer, Junkie is limited in what protocols it
supports and how deep it inspects packets. Here is a quick overview of the
most blatant limitations:

- Ethernet parser supports Linux cooked capture as a special case (used when
  capturing on "any" interfaces) and 802.1q vlan tags. All other Ethernet
  extensions are ignored.

- ARP parser knows only Ethernet and IP addresses.

- DNS parser supports MDNS, NBNS and LLMNR in the extend where these protocols
  mimic legacy DNS (with the exception that it can unscramble NetBios encoded
  names).

- FTP connection tracking merely look for PASSV or PORT commands in the TCP
  stream without much care for the actual protocol.

- Postgresql parser supports only protocol version 3.0 and Mysql parser
  supports only protocol version 10.  This should cover most of the installed
  base, though.

- TNS parser (for Oracle databases) was roughly reverse engineered from
  various sources, especially the wireshark source code. It should thus not
  be expected to understand all messages in all situations.

- SIP parser implements no proprietary extensions, however prevalent.

- VoIP dialogs are identified by their call-id only, which imply that if
  the sniffer listens to various independent SIP proxys or servers then
  call-id collisions can not be ruled out (this choice was made because
  it proven useful in practice).


== Installation

Running configure might tell you that you need:

- guile v2 (2.0.6 recommended)
- libssl
- libpcap
- libltdl (aka libtool runtime lib)

Compiling with GCC is recommended.

Then it's a matter of './configure && make && sudo make install'.
Optionally, 'sudo make setcap' will give any user the permission to sniff
traffic (like anyone else tapping on the wire).

== Running junkie

=== Command line

By default, Junkie loads no plugins nor sniffs any device, thus doing nothing.
You must use the command line to achieve anything. I will not document the
command line with too much details here and will mention only the few options
you're likely to start with; try +--help+ later for a comprehensive list of
options.

The four simplest options are:

- +-i+ to sniff from the named interface. For instance, +-i eth0+.
  You will probably need superuser privileges, though.

- +-r+ to read packets from a pcap savefile. For instance, +-r traffic.pcap+.

- +-f+ to apply a BPF filter (same than tcpdump filter) to any packet sources.

- +-p+ to load a plugin. Junkie comes with a few ones, such as +dumper+ so
  display a short textual description of the packets.

For instance:

    # junkie -i wlan0 -p dumper.so
    Capture: head_len=48, payload=84, dev_id=0, tv=1343079318s 591221us
    Ethernet: head_len=14, payload=70, vlan_id=-1, source=00:26:5e:0a:d2:b9, dest=00:24:d4:51:59:2c, proto=2048
    IPv4: head_len=20, payload=50, version=4, addr=192.168.0.18->192.168.0.254, proto=UDP, ttl=64, frag=DontFrag, id=0x4a1b, Class=0:NonECT
    UDP: head_len=8, payload=42, ports=57312->53
    DNS: head_len=42, payload=0, QUERY, tx_id=659, err_code=0, request_type=A, dns_class=IN, name=ssl.google-analytics.com

    Capture: head_len=48, payload=84, dev_id=0, tv=1343079318s 591614us
    Ethernet: head_len=14, payload=70, vlan_id=-1, source=00:26:5e:0a:d2:b9, dest=00:24:d4:51:59:2c, proto=2048
    IPv4: head_len=20, payload=50, version=4, addr=192.168.0.18->192.168.0.254, proto=UDP, ttl=64, frag=DontFrag, id=0x4a1c, Class=0:NonECT
    UDP: head_len=8, payload=42, ports=57312->53
    DNS: head_len=42, payload=0, QUERY, tx_id=30270, err_code=0, request_type=AAAA, dns_class=IN, name=ssl.google-analytics.com

    ...

Notice that you can open as many interfaces and/or files as you wish and
that Junkie will process them all simultaneously (one thread per packet
source).

Very important remark:

All command line parameters are processed in the same order you write them. In
the example above, +wlan0+ is opened *before* the plugin is loaded (which
makes little difference here). But if we wanted to apply a filter we'd have to
add the +-f+ option *before* the +-i+ or +-r+.  For instance:

    # junkie -i wlan0 -f 'host 192.168.1.2' -r file.pcap -p dumper

is very different from:

    # junkie -f 'host 192.168.1.2' -i wlan0 -r file.pcap -p dumper

In the former case, all packets captured from +wlan0+ and all packets from
host +192.168.1.2+ from the pcap file named "file.pcap" are dumped, while in
the later case only packets from host +192.168.1.2+ are dumped, whatever the
packet source.

== Plugins

Junkie is designed to be extensible but can also be useful all by itself
thanks to the few plugins that ships with it.

Remember that to load a plugin you must run:

    junkie -p pluginname

Also, each plugin adds it's own command line options that you can read help
for with:

    junkie -p pluginname --help


=== Dumper

Dumps to stdout every packets, not unlike tcpdump.

Example:

    # junkie -p dumper -i eth0
    Capture: head_len=48, payload=92, dev_id=0, tv=1372061164s 847010us
    Ethernet: head_len=14, payload=78, vlan_id=-1, source=00:21:70:0c:cb:2c, dest=ff:ff:ff:ff:ff:ff, proto=IPv4
    IPv4: head_len=20, payload=58, version=4, addr=192.168.10.203->192.168.10.255, proto=UDP, ttl=128, frag=NoFrag, id=0x9d28, Class=0:NonECT
    UDP: head_len=8, payload=50, ports=137->137
    DNS: head_len=50, payload=0, QUERY, tx_id=32811, err_code=0, request_type=NB, dns_class=IN, name=BRN001BA9E23A8E

    Capture: head_len=48, payload=1514, dev_id=0, tv=1372061164s 928352us
    Ethernet: head_len=14, payload=1500, vlan_id=-1, source=d4:be:d9:a6:fc:4a, dest=00:10:f3:10:61:30, proto=IPv4
    IPv4: head_len=20, payload=1480, version=4, addr=192.168.10.9->5.135.156.187 (hashed the other way), proto=TCP, ttl=64, frag=DontFrag, id=0x39cb, Class=2:NonECT
    TCP: head_len=32, payload=1448, ports=50200->22(srv), flags=AckPsh, win=730, ack=3224280098, seq=844841801 (0), urg=0, opts=nop,nop,8

    Capture: head_len=48, payload=66, dev_id=0, tv=1372061164s 960546us
    Ethernet: head_len=14, payload=52, vlan_id=-1, source=00:10:f3:10:61:30, dest=d4:be:d9:a6:fc:4a, proto=IPv4
    IPv4: head_len=20, payload=32, version=4, addr=5.135.156.187->192.168.10.9, proto=TCP, ttl=54, frag=DontFrag, id=0x7439, Class=0:NonECT
    TCP: head_len=32, payload=0, ports=22(srv)->50200, flags=Ack, win=1994, ack=844843249, seq=3224280098 (0), urg=0, opts=nop,nop,8

    ....

Much more verbose than `tcpdump` but also easier to read.


=== Writer

Save packets in a pcap (or optionally, CSV) file. Has many options to control
what packets to save.

Example, asking junkie to select only dns message for name "google.com" and
piping the pcap packets into tcpdump:

    # junkie -p writer --file /dev/stdout --netmatch "'(dns) '(dns.name = "'"google.com")' -i eth0 | tcpdump -n -r /dev/stdin
    reading from file /dev/stdin, link-type EN10MB (Ethernet)
    10:25:28.008388 IP 192.168.10.9.36668 > 192.168.10.254.53: 13033+ A?  google.com. (28)
    10:25:28.008756 IP 192.168.10.254.53 > 192.168.10.9.36668: 13033 11/4/0 A 173.194.45.78, A 173.194.45.65, A 173.194.45.68, A 173.194.45.72, A 173.194.45.67, A 173.194.45.64, A 173.194.45.70, A 173.194.45.69, A 173.194.45.73, A 173.194.45.66, A 173.194.45.71 (276)
    10:25:28.009456 IP 192.168.10.9.57805 > 192.168.10.254.53: 12314+ AAAA?  google.com. (28)
    10:25:28.009770 IP 192.168.10.254.53 > 192.168.10.9.57805: 12314 1/4/0 AAAA 2a00:1450:4007:806::100e (128)
    10:25:28.009956 IP 192.168.10.9.46258 > 192.168.10.254.53: 64985+ MX?  google.com. (28)
    10:25:28.010334 IP 192.168.10.254.53 > 192.168.10.9.46258: 64985 5/4/5 MX alt4.aspmx.l.google.com. 50, MX aspmx.l.google.com. 10, MX alt2.aspmx.l.google.com. 30, MX alt3.aspmx.l.google.com. 40, MX alt1.aspmx.l.google.com. 20 (288)

Quoting from command line is getting tricky. Notice how +eth0+ is opened
_after_ the filter is set (or the plugin would receive first packets before
the +--netmatch+ parameter is executed.

The `netmatch` filter is an alternative way to select packets based on
protocolar informations (more powerful but also more complex than the mere BPF
filter available with the +-f+ option).

Netmatch language is somewhat unique in filtering tools in that it allow to
store a state and invoque any C/Scheme functions. More on that later.

=== Rater

Similar to writer but triggers the save based on the rate of packets. Useful
to find out what's causes some burst in bandwidth for instance.

=== Packetogram

Display the distribution of packet sizes. Useful to find out the various MTU
used in a LAN, for instance.

Example:

    junkie -p packetogram -i eth0

Typical display:

           IPv4:  21982/540880  (101.8%)     0-   49:     0,   0.0%
       Ethernet:  21338/531290  (100.0%)    50-   99:  7659,  35.9% -------------------                                                           |
            TCP:  17121/443755  ( 83.5%)   100-  149:   492,   2.3% -   |
           HTTP:   3507/73140   ( 13.8%)   150-  199:   351,   1.6%   |
            UDP:   2618/52396   (  9.9%)   200-  249:   149,   0.7% |
            GRE:    644/9596    (  1.8%)   250-  299:   120,   0.6% |
            TLS:    386/8706    (  1.6%)   300-  349:    68,   0.3%
            FTP:    299/6308    (  1.2%)   350-  399:    49,   0.2%
            DNS:    137/5093    (  1.0%)   400-  449:    61,   0.3%
           ICMP:     36/797     (  0.2%)   450-  499:    92,   0.4%
           ICMP:     36/797     (  0.2%)   500-  549:    66,   0.3%
           IPv6:     35/346     (  0.1%)   550-  599:    99,   0.5% |
          MySQL:      0/47      (  0.0%)   600-  649:    53,   0.2%
            SIP:      0/1       (  0.0%)   650-  699:    36,   0.2%
                                           700-  749:    66,   0.3%
                                           750-  799:  2291,  10.7% -----           |
                                           800-  849:    53,   0.2%
                                           850-  899:    55,   0.3%
                                           900-  949:    46,   0.2%
                                           950-  999:    33,   0.2%
                                          1000- 1049:    33,   0.2%
                                          1050- 1099:    29,   0.1%
                                          1100- 1149:    55,   0.3%
                                          1150- 1199:   132,   0.6% |
                                          1200- 1249:    31,   0.1%
                                          1250- 1299:   215,   1.0%
                                          1300- 1349:   208,   1.0%  |
                                          1350- 1399:    81,   0.4%
                                          1400- 1449:   695,   3.3% -          |
                                          1450- 1499:  1029,   4.8% --    |
                                          1500- 1549:  6992,  32.8% -----------------                                                                 |
                                              count: 21339/531292, min size:    64/   64, max size:  1518/ 1518


The left half of the display shows a decomposition per protocol which show
that an IPv4 datagram is present in 101.8% of packets. Looks dubious until a
closer look reveal that we also have 1.8% of packets with a GRE tunnel, so
with 2 IP datagrams.

The right half of the screen displays an histogram of packet sizes, revealing
that somewhere in the tapped traffic we have an MTU of 800 bytes only.


=== NetTop

Display the heavy hitters, not unlike the famous nettop.
You can choose to group flows by IPs, MACs, ports, and so on (see the +help+).

Example:

    junkie -p nettop -i eth0

Typical display:

    NetTop - Every 1.00s - Tue Dec 13 09:48:25 2011
    Packets: 144317, Bytes: 49144856 (49144856 bytes/sec)

       Packets     Volume                  Protocol                Source    Destination
          5661    8586686         Ethernet/IPv4/TCP       194.51.225.7:80 -> 135.206.251.185:4009
          1436    2179848    Ethernet/IPv4/TCP/HTTP        9.20.214.28:80 -> 194.49.226.10:54190
          1080    1639440     Ethernet/IPv4/TCP/FTP  198.118.195.40:64490 -> 135.206.55.137:55266
           820    1237864         Ethernet/IPv4/TCP     194.49.226.47:443 -> 194.48.220.28:39485
           644     977592         Ethernet/IPv4/TCP      94.211.92.148:80 -> 135.206.199.39:37755
           624     947232         Ethernet/IPv4/TCP  198.118.195.40:60979 -> 135.206.51.8:34456
           406     616308         Ethernet/IPv4/TCP  198.118.195.40:55845 -> 135.206.55.137:55259
           417     596964    Ethernet/IPv4/TCP/HTTP      135.206.84.17:80 -> 131.220.125.26:33258
           362     549516         Ethernet/IPv4/TCP  198.118.195.40:56332 -> 135.206.51.8:34507
           346     525228     Ethernet/IPv4/TCP/FTP  198.118.195.40:55787 -> 135.206.55.137:55260
           345     523710     Ethernet/IPv4/TCP/FTP  198.118.195.40:59358 -> 135.206.55.137:55254
           306     464508     Ethernet/IPv4/TCP/FTP  198.118.195.40:55381 -> 135.206.55.137:55264
           301     456918         Ethernet/IPv4/TCP  198.118.195.40:59685 -> 135.206.55.137:55237
           297     450846         Ethernet/IPv4/TCP  198.118.195.40:63912 -> 135.206.51.8:34520
           337     448866         Ethernet/IPv4/TCP    194.49.180.2:27016 -> 38.107.111.251:52498
           281     423286    Ethernet/IPv4/TCP/HTTP    213.218.150.153:80 -> 135.206.50.57:50096
           277     420486         Ethernet/IPv4/TCP  198.118.195.40:64241 -> 135.206.55.137:55241

Which shows a top of active sockets. In a way similar to top, the +h+ key leads to an help page which allow
to change interactively what's displayed. In particular, you can change what
fields are used to group traffic, so that you can change the default `group by
socket` view to a `group by protocols + MACs` view:

    NetTop - Every 8.00s - Tue Dec 13 09:50:57 2011
    Packets: 423608, Bytes: 340297686 (42537210 bytes/sec)

       Packets     Volume                          Protocol              Source    Destination
        144328  133103337                 Ethernet/IPv4/TCP   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
         71441  100876369            Ethernet/IPv4/TCP/HTTP   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
        120110   40144204                 Ethernet/IPv4/TCP   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
          9257   14024997             Ethernet/IPv4/TCP/FTP   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
         20659   13767085                 Ethernet/IPv4/UDP   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
         11245   12914303            Ethernet/IPv4/TCP/HTTP   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
         17049   11861508                     Ethernet/IPv4   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
         12446    2913406                 Ethernet/IPv4/UDP   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
          3303    2843771             Ethernet/IPv4/TCP/TLS   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
          2609    2630285        Ethernet/IPv4/GRE/IPv4/TCP   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
          1429     727555             Ethernet/IPv4/TCP/TLS   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
          1600     342837             Ethernet/IPv4/UDP/DNS   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
           355     329909   Ethernet/IPv4/GRE/IPv4/TCP/HTTP   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
          1605     176905             Ethernet/IPv4/UDP/DNS   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
           222     145830                Ethernet/IPv4/ICMP   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
            15      11819    Ethernet/IPv4/GRE/IPv4/TCP/TLS   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00
            84       7912         Ethernet/IPv4/IPv6/ICMPv6   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
             9       7154    Ethernet/IPv4/GRE/IPv4/TCP/TLS   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
            46       4822        Ethernet/IPv4/GRE/IPv4/UDP   b4:a5:e3:4d:5c:00 -> 88:44:e1:1d:6d:00
            16       3507    Ethernet/IPv4/GRE/IPv4/UDP/DNS   88:44:e1:1d:6d:00 -> b4:a5:e3:4d:5c:00

=== Duplicogram

Display the distribution of packet duplicates (according to the time interval
between them). Useful to find out how many sources of duplication there are.

Example:

    junkie -p duplicogram --bucket-width 1 -i eth0

Typical display:

    dusp:           636/761252       (  0.08%)
    bytes:       148930/611060778    (  0.02%)
         |  *
         |  *
         |  *
         |  *
         |  *
      122|  *
         |  *
         |  *
         |  *
         |  *
         |  *
      103|  **
         |  **
         |  **
         |  **
         |  **
         |  **
       85|  ***
         |  ***
         |  ***
         |  ***
         |  ***
         |  ***
       66|  ***
         |  ***
         |  ****
         |  ****
         |  ****
         |  ****
       47|  *****
         |  *****
         |  *****
         |  *****
         | ******
         | ******
       29| ******
         | ******
         | *******
         | *******
         | *******
         | *******
       10| *******
         | ********
         | ********** * * *
         +---------------+---------------+---------------+---------------+---------------+---------------+--->
         0               16              32              48              64              80              96 us


Here we have less than 0.1% of dups, arriving after approximately 5us. The
closest switch we mirror traffic from is certainly the only source of duplication.

=== Os Detect

Display the detected operating system per IP addresses.

Example:

    # junkie -p os-detect -i eth0
    195.167.253.19: g:unix:Linux:2.2.x-3.x
    194.49.224.10: g:unix:Linux:2.2.x-3.x
    135.206.159.186: g:win:Windows:NT kernel
    62.62.55.124: g:win:Windows:NT kernel
    194.49.226.10: g:unix:Linux:2.2.x-3.x
    173.19.138.182: g:win:Windows:NT kernel
    190.22.107.82: g:win:Windows:NT kernel
    194.49.226.10: g:unix:Linux:2.2.x-3.x
    ...

To detect OS junkie uses only the TCP fingerprints taken from p0f. If you need
only this information you'd rather be using p0f directly, which provides more
accurate results.

=== ARP graph

Output periodically a dot schema of communicating peers.

Example:

    junkie -p arpgraph -r file.pcap

=== Serializer

Used to send parsed informations to another junkie through a socket.


Although you can use a plugin to perform anything, this is not the way you
will want to run Junkie, though. Instead, you will want to use its extension
language (Guile) to control the sniffer from the inside.

== Taking full control with Guile

Junkie is linked with the Guile Scheme implementation and roughly a hundred of
parameters/functions are available from there. Also, additional
functionalities are merely implemented in scheme as separate threads (SNMP
subagent, Web server, control socket...) You can of course add your own.

So you'd probably want to run Junkie with either the +-c+ (load and execute a
Guile file) or the +-e+ options (execute the given command).

Actually, all command line parameters are scheme commands in disguise
(for instance, +-c file+ is translated into +-e (load "file")+).

Let's try it:

    $ junkie -e "(define (fact n) (if (equal? n 0) 1 (* n (fact (- n 1)))))" \
             -e "(display (fact 100))" \
             -e "(newline)"
    93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000

Ok not very useful but notice how command line arguments are
processed from first to last. For something more entertaining try:

    $ sudo junkie -e "(start-repl-server)" &
    $ rlwrap telnet localhost 29000
    Trying 127.0.0.1...
    Connected to localhost.
    Escape character is '^]'.
    junkie>

Yes this prompt is Junkie waiting for more orders. Go ahead:

    junkie> (open-iface "eth0" #t "udp port 53")
    "eth0"
    junkie> (iface-stats "eth0")
    ((id . 0)
     (nb-packets . 56)
     (nb-duplicates . 0)
     (tot-received . 56)
     (tot-dropped . 0)
     (nb-cap-bytes . 5898)
     (nb-wire-bytes . 5898)
     (file? . #f)
     (filter . "udp port 53"))

Here we opened device "eth0" (like we did earlier with the command line
parameter +-i+) but with the additional argument specifying that we want
to turn the device in promiscuous mode and filter received packets through
the BPF filter "udp port 53" (same libpcap as Tcpdump, thus same BPF filters
syntax). When in doubt, ask for help:

    junkie> (help "open-iface")
    (open-iface "iface-name"): open the given iface, and set it in promiscuous mode.
    (open-iface "iface-name" #f): open the given iface without setting it in promiscuous mode.
    (open-iface "iface-name" #t "filter"): open the given iface in promiscuous mode,
        with the given packet filter.
    (open-iface "iface-name" #t "filter" 90): same as above, but capture only the first
        90 bytes of each packet. Use 0 for all bytes (the default).
    (open-iface "iface-name" #t "[filter]" 90 (* 10 1024 1024)): same as above, using
        a buffer size of 10Mb (instead of system default).
    Will return #t or #f depending on the success of the operation.
    See also (? 'list-ifaces) to have a list of all openable ifaces,
        and (? 'close-iface) to close a given iface


You got the idea (or you need
http://www.gnu.org/software/guile/manual/html_node/index.html[a quick
refresher about Scheme syntax]).

Notice that you don't want to keep this 29000 server _running as root and
executing any scheme command_ any longer.

The following section suppose you are somewhat familiar with Scheme and
Guile.


== Design

=== Main flow of execution

Junkie mainly parses packets one after another in order to provide any
plugin(s) with unscrambled informations instead of raw bytes:

[graphviz]
-------------------------------------------------------------------------------
digraph G {
    node [ fontsize=10 ]
    graph [ rankdir="LR" ]
    libpcap -> junkie [label="packets"]
    junkie -> plugins [label="packets + infos"]
}
-------------------------------------------------------------------------------

More precisely, junkie will first try to eliminate duplicate packets and then
pass each one into a sequence of specialized parsers, reassembling/reordering
in the process and extracting the most useful informations along the way into
simple C structures where the plugin can easily get them. Here is an example
showing the parsing of an HTTP packet:

[graphviz]
-------------------------------------------------------------------------------
digraph G {
    libpcap -> junkie
    node [
        shape=box
        fontsize=10
    ]

    {
        color=blue
        junkie -> deduplication
        deduplication -> Cap

        subgraph parsers {
            Cap -> Eth [ label=" + timestamp, wirelen..." ]
            Eth -> IP [ label=" + MACs, Vlan..." ]
            IP -> TCP [ label=" + IP addresses..." style=dashed ]
            TCP -> HTTP [ label=" + ports, options..." style=dashed ]
        }
    }

    HTTP -> plugin [ label=" + URL, Host..." style=dashed]

    {
        color=blue
        plugin
    }

    junkie [ shape=ellipse ]
    deduplication [ shape=ellipse ]
    plugin [ shape=ellipse ]
}
-------------------------------------------------------------------------------

where the dashed arrows mean that this call can be deferred until more data is
available (for IP reassembly, for TCP reordering or for HTTP headers to be complete...)

=== Deduplication

In some settings, like when port mirroring is used to gather traffic to
Junkie, some packets may be received several times. Whatever you use Junkie
for, it is likely that you want to have these duplicate frames detected and
eliminated.

In order to be able to eliminate duplicate frames quickly and efficiently,
Junkie keeps a list of MD4 digests of previously received frames and some per
network interface statistics. As several packet sources may use the same
underlying network device we have three data structures taking part in
deduplication:

[graphviz]
-------------------------------------------------------------------------------
digraph G {
    node [
        shape=box
        fontsize=10
    ]
    graph [
        rankdir="LR"
        splines=curved
    ]

    queue0 [
        shape=record
        label="<h>digests for eth1|\<&#8710;t\>, &#963;|{MD4 &#8594; TimeStamp0}|{MD4 &#8594; TimeStamp1}|{MD4 &#8594; TimeStamp2}|{...}|{<last>MD4 &#8594; TimeStampN}"
    ]

    queue1 [
        shape=record
        label="<h>digests for eth2|\<&#8710;t\>, &#963;|{MD4 &#8594; TimeStamp0}|{MD4 &#8594; TimeStamp1}|{MD4 &#8594; TimeStamp2}|{...}|{<last>MD4 &#8594; TimeStampN}"
    ]
    info0 [
        shape=plaintext
        label="TimeStampN &#8805; TimeStamp0 + max-dup-delay"
    ]
    info0 -> queue1:last

    sources [
        shape=record
        label="Pkt Sources|{eth1[0]|<s0>Digest}|{eth1[1]|<s1>Digest}|{eth2[0]|<s2>Digest}|{...}"
    ]

    sources:s0 -> queue0:h
    sources:s1 -> queue0:h
    sources:s2 -> queue1:h
}
-------------------------------------------------------------------------------

The only parameter governing deduplication is the maximum delay between two
dup frames, which is set by default to 100ms (+max-dup-delay+ from Guile).
Junkie will never check digests older than this (at the contrary these old
digests will be freed from memory). As a consequence, setting this parameter
to 0 will disable deduplication altogether.

For each incoming packet, junkie will compute its MD4 digest (masking out some
field such as IP's TTL or, optionally, the 802.1q vlan tag), and compare it to
all previous digests, up to +max-dup-delay+. If a packet with same digest and
which came from the same interface is found then the incoming one is merely
discarded (Note: as usual we do not use a single hash of digests but one per
CPU to avoid locking).

If network interfaces are to be collapsed into one, then an additional
deduplication pass is to be performed. Notice that in this case the frame will
be handled twice: the digest will be computed and stored twice. Yes this is
considered a bug.

=== Reassembly, reordering and buffering

To be able to chain parsers from the transport layer up to the application
layers junkie must provide a mecanism to rebuild a stream of bytes from
fragmented or out of order segments, and to buffer temporarily a payload
until a complete message is received.

Reordering and reassembly are done using the +pkt_wait_list+ facility. For
instance, the IP parser uses this to reassemble fragmented packets and TCP
parser uses this to reorder out of order segments.

Buffering is achieved through the +streambuf+ facility. For instance, the
HTTP parser uses this to wait until the HTTP headers are complete before
parsing them.

==== Packet Waiting Lists

IP, TCP and many other protocols based on UDP can receive packets in the wrong
order and must reorder the data before calling their subparsers so that those
can understand their payload.  The basic idea is thus to maintain a list of
out of order packets, provisioned with all incoming packets and dequeuing the
head of the list whenever complete. The purpose of this list is thus to
reorder and wait for missing packets, according to an offset in the stream
that can be TCP sequence number, IP fragment offset, WTP sequence number...

Once created, the user of a +pkt_wait_list+ can then add data to it using
+pkt_wait_list_add+, and this function will take care of calling the
subparser whenever possible and timeouting fragments.

This is more complex that it sounds; remember that all the +proto_info+
structures build by previous parsers lay on the stack, and so must be copied
in the heap when the parse is suspended, so that when eventualy the parse is
resumed (either the gap in sequence number is filled or the pending packets
is timeouted) the subparsers can get called with these +proto_info+
structs and add new infos from there.

Another problem, easier to solve but probably more expensive, is that due to
the way the kernel sends the packets to libpcap we also need to copy the
packet itself.

That's why we try to only push the packets in the waiting list when
this is strictly required; in other words, when we add to a waiting list a
packet that can be processed at once then the parse function is called
directly and the packet is not stored.

Here is for instance two +pkt_wait_list+, sharing the same configuration:

[graphviz]
-------------------------------------------------------------------------------
digraph G {
    node [
        shape=box
        fontsize=10
    ]
    graph [
        rankdir="LR"
        splines=curved
    ]

    config [
        shape=record
        label="<h>pkt_wl_config|acceptable_gap|nb_pkts_max|payload_max|timeout"
    ]

    wl1 [
        shape=record
        label="pkt_wait_list (1)|<p>pkts|<c>config|nb_pkts|tot_payload|next_offset|last_used|parser"
    ]
    wl2 [
        shape=record
        label="pkt_wait_list (2)|<p>pkts|<c>config|nb_pkts|tot_payload|next_offset|last_used|parser"
    ]

    wl1:c -> config:h
    wl2:c -> config:h

    pkt1 [
        shape=record
        label="pkt_wait (1)|<e>entry|offset|next_offset|tot_cap_len|<s>start|cap_len|wire_len|<p>parent|way|packet:|<start>...|<mid>8a d7 67 ab 26 44 21 c9|f2 e7 00 9a 08 19 43 b9|76 bc 28 03 44 25 d1 66|e1 15 91 97 20 bf e8 fe|...|<end>bc a4 d5 9f a2 08 80 47"
    ]
    pkt1:s -> pkt1:mid
    pkt1:mid -> pkt1:end [decorate,fontsize="8",label="+caplen"]
    pkt1:start -> pkt1:end [decorate,fontsize="8",label="+tot_cap_len"]

    pkt2 [
        shape=record
        label="pkt_wait (2)|<e>entry|offset|next_offset|tot_cap_len|<s>start|cap_len|wire_len|<p>parent|way|packet:|85 ce 2e a0 1e 81 e5 09|..."
    ]
    pkt3 [
        shape=plaintext
        label="..."
    ]
    wl1:p -> pkt1:e -> pkt2:e -> pkt3

    pkt4 [
        shape=record
        label="pkt_wait (1)|<e>entry|offset|next_offset|tot_cap_len|<s>start|cap_len|wire_len|<p>parent|way|packet:|fb 09 15 c5 de bc 95 c8|..."
    ]
    pkt5 [
        shape=plaintext
        label="..."
    ]
    wl2:p -> pkt4:e -> pkt5

    info1 [
        shape=record
        label="<h>proto_info (HTTP)|<p>parent|<r>parser|infos..."
    ]
    info2 [
        shape=record
        label="<h>proto_info (TCP)|<p>parent|<r>parser|infos..."
    ]
    info3 [
        shape=plaintext
        label="..."
    ]
    pkt1:p -> info1:h
    info1:p -> info2:h
    info2:p -> info3

    info4 [
        shape=record
        label="<h>proto_info (HTTP)|<p>parent|<r>parser|infos..."
    ]
    info5 [
        shape=record
        label="<h>proto_info (TCP)|<p>parent|<r>parser|infos..."
    ]
    info6 [
        shape=plaintext
        label="..."
    ]
    pkt2:p -> info4:h
    info4:p -> info5:h
    info5:p -> info6

    http [
        shape=record
        label="<h>parser|..."
    ]
    tcp [
        shape=record
        label="<h>parser|..."
    ]
    info1:r -> http:h
    info2:r -> tcp:h
    info4:r -> http:h
    info5:r -> tcp:h
}
-------------------------------------------------------------------------------

Notice in particular that each packet are copied entirely right into the
+pkt_wait+ structure, which is thus of varying size.

When timeouting packets or destroying them for any other reason, plugins
that are subscribed to the packet hook will get called for every fragment so
that the packet count is reliable. The drawback is that the timestamp they
see can jump back in time.

==== Stream Buffers

Most application parsers are concerned about some kind of messages which
boundaries does not correspond to packet boundaries. They receive chunks of
payload from their parent and must wait for a full message to be available
before proceeding. This is were the zero-copy tradition of network sniffing
falls short: insisting in not copying payloads will force these parsers to
handle many tricky pointer arithmetic, which will be quite slow especially
considering the parse is often restarted from the beginning.

That's why, for the +streambuf+ facility, it was chosen to merely copy the
payload in a single, linear memory buffer so that life is easier for applicative
parsers.

Once created, a +streambuf+ provides a parsing function that wrap your parser
own parsing function, adding the ability to give up parsing after a given
offset (your parsing function will then be called again later after some new
content was received, starting from this restart offset). See
+streambuf_set_restart+ for more informations.

[graphviz]
-------------------------------------------------------------------------------
digraph G {
    node [
        shape=box
        fontsize=10
    ]
    graph [
        rankdir="LR"
        splines=curved
    ]

    streambuf [
        shape=record
        label="streambuf|parse|max_size|{{dir[0]|<b0>buffer|buffer_size|restart_offset|buffer_is_malloced|wait}|{dir[1]|<b1>buffer|buffer_size|<r1>restart_offset|buffer_is_malloced|wait}}"
    ]

    buffer0 [
        shape=record
        label="<h>...|28 2f 61 ef c9 2a 09 e5|..."
    ]
    buffer1 [
        shape=record
        label="<h>...|<r>b0 1d 60 31 bd dc 51 58|..."
    ]
    streambuf:b0 -> buffer0:h
    streambuf:b1 -> buffer1:h
    streambuf:r1 -> buffer1:r
}
-------------------------------------------------------------------------------

Notice that we have actually two buffers: one for each direction (since a
parser is required to handle both directions).

=== Hooks

There are several hooks here and there for plugins to subscribe to and be sent
the informations gathered up to there (as well as the whole packet). In
addition to special purpose hooks implemented by a given parser, all parsers
have a completion hook (subscribing parsers will be called after the parser
processed its share of the payload) and there is a global per packet hook that
will be called once per packet after it's fully parsed.

Plugins receive all the informations gathered along the way in a list of C
structure chained together and usually stored on the stack, as well as the
origin packet that was undergoing parsing when the callback was called. It's
not allowed to modify these data but apart from that can do anything.

Be aware that as junkie uses several threads to parse traffic your plugins are
required to be reentrant, and that you can not count on the fact that similar
packets (like the ones of the same TCP socket) will be handled by the same
thread (junkie makes no such assumption nor attempt to guaranty this).


=== Netmatch language

Junkie comes with a language that one can use to match individual packets,
protocol events or sequence of events. Its syntax is similar to scheme
for easier parsing (it should be easy to add a front-end later for another
syntax more similar to wireshark one). It's compiled to native code through
C thanks to +gcc+ (which is then mandatory to use the feature).

The basic principle is to supply expressions that are applied to each packet
(more precisely to each protocolar information stack extracted from the stream
of packets).

A match expression consists of two parts:

- a filter on the protocol stack,
- an expression, using the informations gathered by the selected protocols,
returning a boolean value.

==== Selecting a protocol stack

The filter on the protocol stack consists of a mere list (in Scheme) of
protocol names.  For instance:

    '(cap ip http)

matches any protocol stack with HTTP within IP within Cap (+Cap+ is for
Capture, the virtual protocol representing the sniffing of packet with
libpcap, thus all protocol stack always start with Cap). It's allowed to have
other protocols than that to match this filter, but you must have Cap followed
by IP followed by HTTP. For instance, both +Cap/Eth/IP/TCP/HTTP+ and
+Cap/Eth/IP/GRE/IP/TCP/HTTP+ matches this filter, while +Cap/Eth/IP/TCP+ does
not.

In case where the same protocol appears several time (such as in our previous
example with the sequence +IP/GRE/IP+) then the selected protocol will be the
inner one.

Notice that protocol names being scheme symbols the list must be quoted.

==== Boolean expression

The boolean expression is again a scheme-like expression that can use the
informations gathered from the selected protocols (such as +http.url+ or
+ip.src+), combine them with the usual arithmetic/logic operators (and a few
additional functions), and yield a boolean value.

==== Examples

Rather than giving a comprehensive grammar, here are a few valid examples,
using the writer plugin:

    junkie -i eth0 -p writer.so --method csv --file /dev/stdout --netmatch "'(tcp) '(tcp.src-port == 80)"
    Capture{head_len=48, payload=1518, dev_id=0, tv=1323766041s 448146us}/Ethernet{head_len=18, payload=1500, vlan_id=-1, source=b4:a4:e3:4d:5c:01, dest=88:43:e1:1d:6d:01, proto=2048}/IPv4{head_len=20, payload=1480, version=4, addr=193.51.224.41->134.206.18.234 (hashed the other way), proto=TCP, ttl=59, frag=DontFrag, id=0x50bc, Class=0:NonECT}/TCP{head_len=32, payload=1448, ports=80->58731, flags=Ack, win=232, ack=2700930991, seq=418183969, urg=0, opts=nop,nop,8}
    Capture{head_len=48, payload=1518, dev_id=0, tv=1323766041s 448149us}/Ethernet{head_len=18, payload=1500, vlan_id=-1, source=b4:a4:e3:4d:5c:01, dest=88:43:e1:1d:6d:01, proto=2048}/IPv4{head_len=20, payload=1480, version=4, addr=193.51.224.41->134.206.18.234 (hashed the other way), proto=TCP, ttl=59, frag=DontFrag, id=0x50bd, Class=0:NonECT}/TCP{head_len=32, payload=1448, ports=80->58731, flags=Ack, win=232, ack=2700930991, seq=418185417, urg=0, opts=nop,nop,8}
    ...

    junkie -i eth0 -p writer.so --method csv --file /dev/stdout --netmatch "'(ip udp) '(not (routable? ip.dst))"
    Capture{head_len=48, payload=96, dev_id=0, tv=1323766044s 486570us}/Ethernet{head_len=18, payload=78, vlan_id=-1, source=88:43:e1:1d:6d:01, dest=b4:a4:e3:4d:5c:01, proto=2048}/IPv4{head_len=20, payload=58, version=4, addr=134.206.57.39->169.254.31.38, proto=UDP, ttl=126, frag=NoFrag, id=0x55c2, Class=0:NonECT}/UDP{head_len=8, payload=50, ports=2008->161}
    Capture{head_len=48, payload=629, dev_id=0, tv=1323766044s 706148us}/Ethernet{head_len=18, payload=611, vlan_id=-1, source=88:43:e1:1d:6d:01, dest=b4:a4:e3:4d:5c:01, proto=2048}/IPv4{head_len=20, payload=591, version=4, addr=134.206.80.237->192.168.84.2, proto=UDP, ttl=61, frag=NoFrag, id=0x77a9, Class=0:NonECT}/UDP{head_len=8, payload=583, ports=60748->3052}
    ...


=== Nettrack language

Using netmatch language one can build a finite state machine with match
expressions as edges. Together with the ability to save some values from state
to state, and the ability to execute arbitrary code when entering a vertex,
one can track any succession of network events.

Here is an example, printing all DNS queries which answer is seen more than
150ms after the query (detailed explanations follow):

    (use-modules ((junkie netmatch nettrack) :renamer (symbol-prefix-proc 'nt:)))
    (define slow-dns (nt:compile "slow-dns"
      '(; registers
        [(client-ip ip)
         (server-ip ip)
         (qry-start timestamp)
         (qry-stop timestamp)
         (qry-name str)]
        ; vertices
        [(dns-slow-answer
           (on-entry (pass "printf(\"%s\\t%s\\t%s\\t%\"PRIuPTR\"\\t%s\\n\",
                            ip_addr_2_str(" client-ip "), ip_addr_2_str(" server-ip "),
                            timeval_2_str(" qry-start "),
                            " (timestamp-sub qry-stop qry-start) ", " qry-name ");\n")))
         (dns-query
           (index-size 1024))]
        ; edges
        [(root dns-query
            (match (cap ip dns) (if dns.query
                                  (do
                                    (client-ip := ip.src)
                                    (server-ip := ip.dst)
                                    (txid := dns.txid)
                                    (qry-name := dns.name)
                                    (qry-start := cap.ts)
                                    #t)))
            (dst-index-on () txid)
            spawn)
         (dns-query dns-fast-answer
            (match (cap ip dns) (if
                                  (and
                                    (ip.src == server-ip)
                                    (ip.dst == client-ip)
                                    (dns.txid == txid))
                                  (do
                                    (qry-stop := cap.ts)
                                    #t)))
            (src-index-on (dns) dns.txid))
         (dns-query dns-slow-answer
            (match (cap ip dns) (if
                                  (and
                                    (ip.src == server-ip)
                                    (ip.dst == client-ip)
                                    (dns.txid == txid)
                                    ((timestamp-sub cap.ts qry-start) > 150000))
                                  (do
                                    (qry-stop := cap.ts)
                                    #t)))
            (src-index-on (dns) dns.txid))])))

You can see there are three sections:

- the register file, where some variable and their type can be declared explicitely,
- the vertex definitions, to set the non-default parameters for the vertices,
- the edge list, with the source and destination vertices followed by the transition condition.

==== Registers

You can bind any value to any register using the +:=+ operator. Each register
has a type which is checked along the compilation, amongst unsigned
integer (+uint+), boolean (+bool+), timestamp (+timestamp+), ip address
(+ip+), ethernet address (+mac+), string (+str+), array of bytes (+bytes+)...
Type inference being quite limited it is often required to declare the
register types, thus this special declaration section.

In the above example we declare all the register we'll use: client-ip and
server-ip (as +ip+), qry-start and qry-stop (as +timestamp+) and qry-name (as
+str+).

==== Vertices

As declaring register is not (always) mandatory, declaring vertices is also
optional. You only need to do so when you want to set special attributes.
Here we declare only two vertices (out of the four used), dns-slow-answer,
which is the vertex we enter after a delayed answer is received, because we
want to perform a special action when a state enter this vertex (here, printf
some of our registers to report the slow DNS queries), and dns-query, to ask
for an index (more on that later).

==== Edges

Then follow the description of the edges, consisting of: the source vertex,
the destination vertex, the condition to met for transiting from the former
to the later, and a set of flags. In the above example, apart from the flags
controlling the use of the index (+src-index-on+ and +dst-index-on+), which
explanation will came later, the only flag used is +spawn+, which means that
instead of leaving the source vertex we should instead *spawn* a new state in
the destination vertex (with a copy of the original registers).

This is important to notice that the conditions will be checked from the last
edge to the first; the idea is that it's more natural to describe the graph
from the +root+ vertex while it's generally more useful to have the leaves
tested before the root.

So the above example could be schematically represented as:

[graphviz]
-------------------------------------------------------------------------------
digraph G {
    node [ fontsize=10 ]
    root -> "dns-query" [ style=dashed label="3) on any DNS,\l saving the query identifiers" ]
    "dns-query" -> "dns-fast-answer" [ label="2) if match the\l saved identifiers" ]
    "dns-query" -> "dns-slow-answer" [ label="1) if match the\l saved identifiers\l and DT > 150ms" ]
}
-------------------------------------------------------------------------------

==== Step by step explanation of the example

Initially, a single state will be created in the vertex named +root+.

Then, for each packet Junkie will check each edges in turn (starting for the
last one aka the deepest). After some time, a DNS query will be met, which is
the only criteria to satisfy the condition to spawn a new state from root to
dns-query. Additionally, some parameters of this event will be saved in
registers: IP addresses, DNS transaction id, queried name and timestamp of the
packet (notice how timestamp is an information provided by the fake +Capture+
protocol).

Eventually, before this request is answered, others DNS queries will be met,
leading to other new states (with different registers) spawned in dns-query.

After some more time another DNS message is received with same transaction-id
than the one in register +txid+, same source IP address as server-ip and same
destination address as client-ip of the first register file we spawned in
dns-query state. Junkie will first check the third edge (from dns-query to
dns-slow-answer).

Let's say this packet timestamp is such that the fourth term
of the +and+ holds as well (ie. slow answer) then the whole condition yields
true, and the state (aka the register file, really) is removed from dns-query
and moved into dns-slow-query. As set by the +on-entry+ directive, the printf
is executed and a line with all this DNS transaction parameters is printed.
Then, the state is dismissed (since the dns-slow-answer is a leaf state).

If, on the contrary, the answer timestamp was close enough to the one saved in
qry-start, then the condition would yield false, and Junkie would have tried
the next edge, from dns-query to dns-fast-answer. This time the register file
would have met all requirement and would have been moved into dns-fast-answer
where it then would have been dismissed for the same reason, but this time
quietly.

==== Let's try

Go ahead and run Junkie (with the repl-server), then copy-paste the above
definition of slow-dns, followed by:

    (nettrack-start slow-dns)

which will effectively start match your graph against the sniffed traffic (you
may see some warning emmited from +gcc+ but that's ok). Try to query various
DNS servers located far away and you should see some dump of the slow queries
on Junkie's stdout.

Some ideas of what can be done with this:

- log every transactions based on any criterion such as response time
- control your firewall to ban clients on successive 404 HTTP errors
- or to open some ports after some complex port-knocking scheme was detected
- save all packets between such and such events
- ...!



